{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkhucgN9tXhM7YzZeYib5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhoangce/tensorflow_learning_stuff/blob/main/automatic_differentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2d0XVK_Swtcp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient tapes\n",
        "\n",
        "TensorFlow provides the `tf.GradientTape` APi for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually `tf.Variable`s. TensorFlow \"records\" relevant operations executed inside the context of a `tf.GradientTape` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation."
      ],
      "metadata": {
        "id": "MG4tVXsmw6-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x**2"
      ],
      "metadata": {
        "id": "COOT_jFZxjxK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once some operations are recorded, use `GradientTape.gradient(target, sources)` to calculate the gradient of some target (often a loss) relative to some source (often the model's variables):"
      ],
      "metadata": {
        "id": "YlvPvsguxq4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dy_dx = tape.gradient(y, x)\n",
        "dy_dx.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2urdlWyFwZ",
        "outputId": "4e676df8-b7a7-4c22-9a05-a1cc2c931ef1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor\n",
        "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
        "b = tf.Variable(tf.zeros(2, dtype=tf.float32, name='b'))\n",
        "x = [[1., 2., 3.]]\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y = x @ w + b\n",
        "  loss = tf.reduce_mean(y**2)"
      ],
      "metadata": {
        "id": "mR356xXByKO4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the gradient of `loss` with respect to both variables, we can pass both as sources to the gradient method. The tape is flexible about how sources are passed and will accept any nested combination of lists or dictionaries and return the gradient structured the same way."
      ],
      "metadata": {
        "id": "eiyEsPwXy1z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[dl_dw, dl_db] = tape.gradient(loss, [w, b])\n",
        "dl_dw, dl_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUQQqIIXzIxF",
        "outputId": "36722690-cefd-4e2c-f0f6-cf6de57eda35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[0.17393541, 1.9080842 ],\n",
              "        [0.34787083, 3.8161683 ],\n",
              "        [0.52180624, 5.7242527 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.17393541, 1.9080842 ], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape, dl_dw.shape, b.shape, dl_db.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGJU2c5fzPn2",
        "outputId": "aeae4997-ee2a-469c-aadf-c3f5dfd7e13b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([3, 2]), TensorShape([3, 2]), TensorShape([2]), TensorShape([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate gradient with a dictionary of variables passed in\n",
        "my_vars = {\n",
        "    'w': w,\n",
        "    'b': b\n",
        "}\n",
        "\n",
        "grad = tape.gradient(loss, my_vars)\n",
        "grad['b']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_qLeWKwzY27",
        "outputId": "21ccef5a-ef87-4b15-f8b0-c69c8829b9c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.17393541, 1.9080842 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradients with respect to a model\n",
        "\n",
        "It's common to collect `tf.Variable` into a `tf.Module` or one of its subclasses (layer.Layer, keras.Model) for checkpointing or exporting.\n",
        "\n",
        "In most cases, we wull watnt o calculate gradients with respect to a model's trainable variables. Since all subsclasses of `tf.Module` aggregate their vairbales in the `Module.trainable_variables` propety, we can calculate these gradients in a few lines of code:"
      ],
      "metadata": {
        "id": "-MQa5NFjzoOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = tf.keras.layers.Dense(2, activation='relu')\n",
        "x = tf.constant([[1., 2., 3.]])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  # Forward pass\n",
        "  y = layer(x)\n",
        "  loss = tf.reduce_mean(y**2)\n",
        "\n",
        "\n",
        "# Calculate gradients with respect to every trainable variable\n",
        "grad = tape.gradient(loss, layer.trainable_variables)\n"
      ],
      "metadata": {
        "id": "NGSAUE9I083K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var, g in zip(layer.trainable_variables, grad):\n",
        "  print(f\"{var.name}, shape: {g.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoXcR8621VHu",
        "outputId": "9b4d041f-4f9b-4035-e214-5779fd6ad6a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kernel, shape: (3, 2)\n",
            "bias, shape: (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Controlling what the tape watches\n",
        "\n",
        "The default behavior is to record all operations after accessing a trainable `tf.Variable`, because:\n",
        "\n",
        "* The tape needs to know which operations to record in the forward pass to calculate the gradietns in the backwards pass.\n",
        "\n",
        "* The tape holds references to intermediate outputs, so we don't want to record unnecessary operations.\n",
        "\n",
        "* The most common use case involves calculating the gradient of a loss with respect to all of a model's trainable variables."
      ],
      "metadata": {
        "id": "Xrlwy6N91jRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This example fails to calculate the gradients because tf.Tensor is not \"watched\" by default, and tf.Variable is not trainable\n",
        "\n",
        "# A trainable variable\n",
        "x0 = tf.Variable(3.0, name='x0')\n",
        "\n",
        "# Not trainable\n",
        "x1 = tf.Variable(3., name='x1', trainable=False)\n",
        "\n",
        "# Not a Variable: A Variable + tensor returns a tensor\n",
        "x2 = tf.Variable(2., name='x2') + 1.0\n",
        "\n",
        "# not a Variable\n",
        "x3 = tf.constant(3., name='x3')\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = (x0**2) + (x1**2) + (x2**2)\n",
        "\n",
        "grad = tape.gradient(y, [x0, x1, x2])\n",
        "\n",
        "for g in grad:\n",
        "  print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG45aVLI3Abz",
        "outputId": "cff5608c-084b-416f-8138-0cb36dfaeb4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the variables being watched by the tape\n",
        "[var.name for var in tape.watched_variables()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX3LBIV534Ys",
        "outputId": "f5041c5f-a214-4b5f-f8be-77466949114f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x0:0']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.GradientTape` provides hooks that give the user control over what is or is not watched.\n",
        "\n",
        "To record gradients with respect to a `tf.Tensor`, call `GradientTape.watch()`:"
      ],
      "metadata": {
        "id": "LFG711BK4MZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = x**2\n",
        "\n",
        "dy_dx = tape.gradient(y, x)\n",
        "dy_dx.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7opllJVStSE",
        "outputId": "c5c761f7-c410-443a-8da4-ad40bd7cfae3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To disable the default behavior of warching all `tf.Variables`, set `watch_accessed_variables=False` when creating the gradient tape. This calculation uses two variables, but only connects the gradient for one of the variables:"
      ],
      "metadata": {
        "id": "O9IpBAaWS5A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = tf.Variable(0.)\n",
        "x1 = tf.Variable(10.)\n",
        "\n",
        "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "  tape.watch(x1)\n",
        "  y0 = tf.math.sin(x0)\n",
        "  y1 = tf.nn.softplus(x1)\n",
        "  y = y0 + y1\n",
        "  ys = tf.reduce_sum(y)"
      ],
      "metadata": {
        "id": "00lJz4O6TlPb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since `GradientTape.watch` was not called on *x0*, no gradient is computed with respect to it:"
      ],
      "metadata": {
        "id": "l82zW6RjT7a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dyx/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\n",
        "grad = tape.gradient(ys, {'x0': x0,\n",
        "                          'x1': x1})\n",
        "\n",
        "print(f\"dy/dx0 = {grad['x0']}\")\n",
        "print(f\"dy/dx1 = {grad['x1']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1HjW0BFUF8I",
        "outputId": "385222f2-49ce-4380-8960-aeca0655c5d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx0 = None\n",
            "dy/dx1 = 0.9999545812606812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intermediate results\n",
        "\n",
        "We can also request gradients of the output with respect to intermediate values computed inside the `tf.GradientTape` context."
      ],
      "metadata": {
        "id": "8LZoZQvXUYx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "\n",
        "# Use the tape to compute the gradient of z with respect to the intermediate value y.\n",
        "# dx_dy = 2 * y and y = x**2 = 9\n",
        "tape.gradient(z, y).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7ZrsuvLU8jG",
        "outputId": "b69dc310-a9d0-4379-92cc-b2863e0b2511"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(18.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the resources held by a `GradientTape` are released as soon as the `GradientTape.gradient` method is called. To compute multiple gradients over the same computation, create a gradient tape with `persistent=True`. This allows multiple calls to the gradient method as resources are released when the tape object is garbage collected."
      ],
      "metadata": {
        "id": "6BQwag6QVV7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([1, 3.])\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  y = x*x\n",
        "  z = y*y\n",
        "\n",
        "  print(tape.gradient(z, x).numpy())\n",
        "  print(tape.gradient(y, x).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2f83y6_VxYW",
        "outputId": "37dfe4b3-6c1d-4f6f-e4c2-ab13ff4e4568"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  4. 108.]\n",
            "[2. 6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del tape # Drop the reference to the tape"
      ],
      "metadata": {
        "id": "TBZb2II6WLfG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes on performance\n",
        "\n",
        "* There is a tiny overhead associated with doing operations inside a gradient tape context. For most eaget execution this will not be a noticeable cost, but we should stil use tape context around the areas only wehre it is required.\n",
        "\n",
        "* Gradient tapes use memory to store intermediate results, including inputs and outputs, for use during the backward pass.\n",
        "\n",
        "For efficiency, some ops (like `ReLU`) don't need to keep their intermediate results and they are pruned during the forward pass. However, if `persistent=True` is set on the tape, nothing is discarded and our peak memory usage will be higher."
      ],
      "metadata": {
        "id": "y574oGPDWueT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradients of non-scalar targets\n",
        "\n",
        "A gradient is fundamentally an operation on a scalar"
      ],
      "metadata": {
        "id": "mc_UCRhNXf18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y0 = x**2\n",
        "  y1 = 1 / x\n",
        "\n",
        "print(tape.gradient(y0, x).numpy())\n",
        "print(tape.gradient(y1, x).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJR_oeHlXmUh",
        "outputId": "60f08be5-1cd7-4fd2-8fbf-c1349c79e39e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n",
            "-0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, if we ask for the gradient of multiple targets, the result for each source is:\n",
        "\n",
        "* the gradient of the sum of the targets, or equivalently\n",
        "* the sum of the gradients of each target"
      ],
      "metadata": {
        "id": "qGJod6KnX0rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y0 = x**2\n",
        "  y1 = 1 / x\n",
        "\n",
        "  print(tape.gradient({'y0': y0,\n",
        "                       'y1': y1}, x).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS5qqulKYoCi",
        "outputId": "9ea5f46e-ab89-4d9a-b129-de0f3aa3d9b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, if the target(s) are not scalar the gradient of the sum is calculated:"
      ],
      "metadata": {
        "id": "88BJjyIpY7C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x * [3., 4.]\n",
        "\n",
        "print(tape.gradient(y, x).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2jZU6mMZLL9",
        "outputId": "0f027609-60cb-4551-8ef5-b8fbb26a4ae6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This makes it simple to take the gradient of the sum of a collection of losses, or the gradient of the sum of an element-wise loss calculation.\n",
        "\n",
        "If we need a separate gradient for each item, we use Jacobian matrix.\n",
        "\n",
        "In some case we can skip the Jacobian. For an element-wise calculation, the gradient of the sum gives the derivative of each element wiuth respect to its input-element, since each element is independent."
      ],
      "metadata": {
        "id": "gdw5R0iJZVb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.linspace(-10., 10., 200+1)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = tf.nn.sigmoid(x)\n",
        "\n",
        "dy_dx = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "9jcDjW4MeZF2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x, y, label='y')\n",
        "plt.plot(x, dy_dx, label='dx/dx')\n",
        "plt.legend()\n",
        "_= plt.xlabel('x')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Ux_HLp_BemrE",
        "outputId": "13bde389-326f-46b8-d62e-a328392307b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control flow\n",
        "\n",
        "Because ta gradient tape recordds operations as they are executed, Python control flow is naturally handled (if and while statement)\n"
      ],
      "metadata": {
        "id": "t9eyOXxuexIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(1.)\n",
        "\n",
        "v0 = tf.Variable(2.)\n",
        "v1 = tf.Variable(2.)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  if x > 0.0:\n",
        "    result = v0\n",
        "  else:\n",
        "    result = v1**2\n",
        "\n",
        "dv0, dv1 = tape.gradient(result, [v0, v1])\n",
        "\n",
        "dv0, dv1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVbeGoILfZAC",
        "outputId": "7dd0ca17-d637-46d2-f3d5-588c320db06a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, None)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cases where gradient returns **None**\n",
        "\n",
        "When a target is not connected to a source, `gradient` will return `None`"
      ],
      "metadata": {
        "id": "pWL8Ur-Mfuoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.)\n",
        "y = tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = y * y\n",
        "print(tape.gradient(z, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGxwbWOWgpMX",
        "outputId": "8e67ee52-6f97-4454-c0d0-8e70f93c2a17"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here `z` is obvioulsy not connected to `x`, but there are several less-obvious ways that a gradient can be disconnected."
      ],
      "metadata": {
        "id": "V-jAuYxAg5ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Replaced a variable with a tensor\n",
        "\n",
        "One common error is to inadvertently replace a `tf.Variable` with a `tf.Tensor`, instead of using `Variable.assign` to update the `tf.Variable`."
      ],
      "metadata": {
        "id": "EndT70tohFRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.)\n",
        "\n",
        "for epoch in range(2):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y = x+1\n",
        "\n",
        "  print(type(x).__name__, \":\", tape.gradient(y, x))\n",
        "  x = x + 1 # This should `x.assign_add(1)"
      ],
      "metadata": {
        "id": "pAGHxEuYhU3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ded21b1-9600-42a5-b18b-0fb8aba1d908"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceVariable : tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "EagerTensor : None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Did calculation outside of TensorFlow\n",
        "\n",
        "The tape can't record the gradient path if the calculation exits TensorFlow."
      ],
      "metadata": {
        "id": "68zBMI-Nhjxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable([[1., 2.],\n",
        "                 [3., 4.]], dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  x2 = x**2\n",
        "\n",
        "  # This step is calculated with NumPy\n",
        "  y = np.mean(x2, axis=0)\n",
        "\n",
        "  # Like most ops, recude_mean will cast the NumPy array to a constant tensor\n",
        "  # using `tf.convert_to_tensor`\n",
        "  y = tf.reduce_mean(y, axis=0)\n",
        "\n",
        "print(tape.gradient(y, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0mwUKwPiCCi",
        "outputId": "23a42bcc-e4d0-482f-faa8-1507f2def7b4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Took gradients through an integer or string\n",
        "\n",
        "Integers and strings are not differentiable. If a calculation path uses these data types there will be no gradient.\n",
        "\n",
        "Nobody expects strings to be differentiable, but it's easy to accidentally create an `int` constant or variable if we don't specify the `dtype`:\n"
      ],
      "metadata": {
        "id": "nSlg71s9iaKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(10)\n",
        "\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = x * x\n",
        "\n",
        "print(g.gradient(y, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9moS1hhbi-gI",
        "outputId": "6f730119-7351-4429-8820-4f483aa5d0a9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow doesn't automatically cast between types so, in practice, we'll often get a type error instead of missing gradient.\n",
        "x = tf.constant(10, dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = x**2\n",
        "\n",
        "print(g.gradient(y, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NSfoAlejIDD",
        "outputId": "19d31e38-860e-4a5c-838f-6fcf3df74402"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(20.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Took gradients through a stateful object\n",
        "\n",
        "State stops gradients. When we read from stateful object, the tape can only observe the current state, not the history that lead to it.\n",
        "\n",
        "A `tf.Tensor` is immutable. WE can't change a tensor once it's created. It has a value, but no state. All the operations discussed so far are also stateless: the output of a `tf.matmul` only depends on its inputs.\n",
        "\n",
        "A `tf.Variable` has internal state - its value. When we use the variable, the state is read. It's normal to calculate a gradient with respect to a variable, but the variable's state blocks gradient calculations from going farther back."
      ],
      "metadata": {
        "id": "JhdRd-TjjjgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = tf.Variable(3.)\n",
        "x1 = tf.Variable(0.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  # Update x1 = x1 + x0\n",
        "  x1.assign_add(x0)\n",
        "  # The tape starts recording from x1\n",
        "  y = x1**2 # y = (x1 + x0) **2\n",
        "\n",
        "# This doesn't work\n",
        "print(tape.gradient(y, x0)) # dy/dx0 = 2*(x1 + x0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aZogcd9kPVj",
        "outputId": "66fd329c-1d56-4c77-fef8-8c2a76c479fb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, `tf.data.Dataset` iterators and `tf.queue` are stateful, and will stop all gradients on tensors that pass through them."
      ],
      "metadata": {
        "id": "XDQJmYkWk06H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## No gradients registered\n",
        "\n",
        "Some `tf.Operation`s are **registered as being non-differentiable** and will return `None`. Others have **no gradient registered**.\n",
        "\n",
        "If we attempt to take a gradient through a float op that has no gradient registered the tape will throw an error instead of silently returning `None`. This way we know something has gone wrong.\n",
        "\n",
        "For example, the `tf.image.adjust_contrast` function wraps `raw_ops.AdjustConstrastv2`, which could have a gradient but the gradient is not implemented."
      ],
      "metadata": {
        "id": "3FdYOEULlMi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.Variable([[[0.5, 0., 0.]]])\n",
        "delta = tf.Variable(0.1)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  new_image = tf.image.adjust_contrast(image, delta)\n",
        "\n",
        "try:\n",
        "  print(tape.gradient(new_image, [image, delta]))\n",
        "  assert False; # this should not happen\n",
        "except LookupError as e:\n",
        "  print(f'{type(e).__name__} : {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZIBhu0emnKR",
        "outputId": "9e5daf53-ca20-483e-fb09-bb01b02aaf9e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LookupError : gradient registry has no entry for: AdjustContrastv2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we need to differentiate through this op, we'll either need to implement the gradient and register it (using `tf.RegisterGradient`) or re-implement the function using other ops."
      ],
      "metadata": {
        "id": "6CVStKoXnDEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros instead of None\n",
        "\n",
        "In some cases it would be convenient to get 0 instead of *None* for unconnected gradients. We can decide what to return when we have unconnected gradients using the `unconnected_gradients` argument:"
      ],
      "metadata": {
        "id": "IH0JkUE2nrw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable([2., 2.])\n",
        "y = tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = y**2\n",
        "\n",
        "print(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EXvHwDIn56z",
        "outputId": "17ff2310-6334-4226-9af2-16f0307ae04d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "meTmKTv2oKLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}